---
title: "CFB"
output: html_document
date: "2022-09-13"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(Hmisc)
library(cfbfastR)
```

```{r}
install.packages("cfbfastR")
```

```{r}
install.packages("tictoc")
```

```{r}
tictoc::tic()
pbp <- data.frame()
seasons <- 2014:cfbfastR:::most_recent_cfb_season()
progressr::with_progress({

  pbp <- cfbfastR::load_cfb_pbp(seasons)
})
tictoc::toc()
```

```{r}
glimpse(pbp)
```

```{r}
#which team has had the most penalties on the first play of a series?
pbp %>%
  filter(new_series == 1, drive_play_number == 1, play_type == 'Penalty', down == 1) %>%
  group_by(year) %>%
  summarize(plays = n(), games = n_distinct(game_id)) %>%
  arrange(desc(plays))
```

#College Football Regression Analysis Assignment

```{r}
logs <- read_csv("http://mattwaite.github.io/sportsdatafiles/footballlogs1121.csv")
  
head(logs)

logs <- logs %>%
  mutate(PointDifferential = TeamScore - OpponentScore)

#Create a regression investigating whether the number of penalties can predict the score differential.
fit <- lm(PointDifferential ~ Penalties, data = logs)
summary(fit)
```
  
#In a paragraph below, describe the results: what is the p-value, and does it mean the results are random? Using the r-squared value, how much of the differential can be explained by penalty yards? How useful is this regression?

p-value: 0.01856
R-squared: 0.0002627 
Because our p-value is less than 0.05, we know that the relationship between point differential and penalties is statistically significant, or not the relationship is not random. But when we turn to the r-squared value, which measures the percent of how much the two are related, we see that it is less than 1%, so point differential and penalties aren't related at all. In other words, there is less than 1% of the difference in differential with the penalties. So, to answer the question of how much of the differential can be explained by penalty yards? Not much, really. This regression is not that helpful because it turns out that our two variables in this case are not that related to each other. Also of note, the residual standard error is 22.76 (meaning that our predictive range is pretty large), which tells us that there is a decent amount of error in this model. And one more thing: the min/max residual values are -80 to 81, meaning that a team underperformed the model's prediction by 80 and one team overperformed by 81, so it missed games by those values when trying to predict certain outcomes and scores. The farther apart our residual values are, the worse the model is.

#Next, create a multiple regression model. Instead of using the number of penalties alone, combine other numeric columns that describe mistakes/bad outcomes to try and predict the score differential with a higher degree of confidence. Look at the same values in the results you did before, but also take into account the residual standard error and the risk of multicollinearity - are you adding columns that explain each other instead of the differential? Below this code block, explain your choices and what you think the results say.

```{r}
#I was curious about the differentials for all the "bad outcome" columns.
logs <- logs %>%
  mutate(
    FirstDownPenDifferential = FirstDownPen - DefFirstDownPen,
    PenYdsDifferential = PenaltyYds - DefPenaltyYds,
    PenDifferential = Penalties - DefPenalties,
    FumbleDifferential = Fumbles - DefFumbles,
    InterceptionsDifferential = Interceptions - DefInterceptions,
    TurnoverDifferential = TotalTurnovers - DefTotalTurnovers)

#Turnovers are bad
model1 <- lm(PointDifferential ~ InterceptionsDifferential + FumbleDifferential, data=logs)
summary(model1)
#p-value: 2.2e-16
#R-squared: 0.2499 
#Min residual: -79.612
#Max residual: 78.996
#RSE: 19.72

#My thought process here is that int and fum are two of the worst outcomes you can have, so they must be related to point differential. I didn't throw in turnover differential because it stands to reason that TO are made up of int and fum. In other words, having a model with all three would just be adding columns that explain each other instead of the differential. What I learned: Our p-value shows that this is not random, and our r-squared predicts about a quarter of the the factors that impact point differential can be attributed to int and fum. Where we get into trouble is with the min/max residuals and RSE. the m/m values are really far apart, and we have a large range of residual standard error. So while the thought behind this model was sound, it isn't the strongest.

#Turnovers and penalty yards are worse...?
model2 <- lm(PointDifferential ~ TurnoverDifferential + PenYdsDifferential, data=logs)
summary(model2)
#p-value: 2.2e-16
#R-squared: 0.2321 
#Min residual: -79.721
#Max residual: 82.474
#RSE: 19.95

#My thinking here 

#INT, FUM, PENYDS must be the worst, right?
model3 <- lm(PointDifferential ~  InterceptionsDifferential + FumbleDifferential + PenYdsDifferential, data=logs)
summary(model3)
#p-value: 2.2e-16
#R-squared: 0.2499 
#Min residual: -79.670
#Max residual: 79.104
#RSE: 19.72
```

#Use filter to narrow the game data so that you're only working with games that are close (you'll need to define what "close" means). Are your simple or multiple regression models better? Worse? Below this code block, explain your choices and what you think the results say.

```{r}
close_games <- logs %>%
  filter(PointDifferential < 9, PointDifferential >-9)

model_close_games <- lm(PointDifferential ~ InterceptionsDifferential + FumbleDifferential, data=close_games)
summary(model_close_games)
#p-value: 2.2e-16
#R-squared: 0.09807 
#Min residual: -11.2655
#Max residual: 11.1263
#RSE: 4.789

model_close_games2 <- lm(PointDifferential ~ InterceptionsDifferential + FumbleDifferential + PenYdsDifferential, data=close_games)
summary(model_close_games2)
#p-value: 2.2e-16
#R-squared: 0.09827 
#Min residual: -11.3417
#Max residual: 11.2030
#RSE: 4.788
```



#At the end of all that code, summarize what you've learned about the relationship between penalties and point differential and whether you think there's a story there or whether it's useful in adding context within a larger story. Would you use this in journalism and, if so, how?







