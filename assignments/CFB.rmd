---
title: "CFB"
output: html_document
date: "2022-09-13"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(Hmisc)
library(cfbfastR)
```

```{r}
install.packages("cfbfastR")
```

```{r}
install.packages("tictoc")
```

```{r}
tictoc::tic()
pbp <- data.frame()
seasons <- 2014:cfbfastR:::most_recent_cfb_season()
progressr::with_progress({

  pbp <- cfbfastR::load_cfb_pbp(seasons)
})
tictoc::toc()
```

```{r}
glimpse(pbp)
```

```{r}
#which team has had the most penalties on the first play of a series?
pbp %>%
  filter(new_series == 1, drive_play_number == 1, play_type == 'Penalty', down == 1) %>%
  group_by(year) %>%
  summarize(plays = n(), games = n_distinct(game_id)) %>%
  arrange(desc(plays))
```

#College Football Regression Analysis Assignment

```{r}
logs <- read_csv("http://mattwaite.github.io/sportsdatafiles/footballlogs1121.csv")
  
head(logs)

logs <- logs %>%
  mutate(PointDifferential = TeamScore - OpponentScore)

#Create a regression investigating whether the number of penalties can predict the score differential.
fit <- lm(PointDifferential ~ Penalties, data = logs)
summary(fit)
```
  
#In a paragraph below this code block, describe the results: what is the p-value, and does it mean the results are random? Using the r-squared value, how much of the differential can be explained by penalty yards? How useful is this regression?

p-value: 0.01856
R-squared: 0.0002627 
Because our p-value is less than 0.05, we know that the relationship between point differential and penalties is statistically significant, or not the relationship is not random. But when we turn to the r-squared value, which measures the percent of how much the two are related, we see that it is less than 1%, so point differential and penalties aren't related at all. In other words, there is less than 1% of the difference in differential with the penalties. In conclusion, this regression is not that helpful because it turns out that our two variables in this case are not that related to each other. Also of note, the residual standard error is 22.76, which tells us that there is a decent amount of error in this model, meaning that our predictive range is pretty large. And one more thing: the min/max residual values are -80 to 81, meaning that our model missed games by those values when trying to predict certain outcomes and scores. The farther apart our residual values are, the worse the model is.

```{r}
#I was curious about the differentials for all the "bad outcome" columns.
logs <- logs %>%
  mutate(
    FirstDownPenDifferential = FirstDownPen - DefFirstDownPen,
    PenYdsDifferential = PenaltyYds - DefPenaltyYds,
    PenDifferential = Penalties - DefPenalties,
    FumbleDifferential = Fumbles - DefFumbles,
    InterceptionsDifferential = Interceptions - DefInterceptions,
    TurnoverDifferential = TotalTurnovers - DefTotalTurnovers)

#Turnovers are bad
model1 <- lm(PointDifferential ~ InterceptionsDifferential + FumbleDifferential, data=logs)
summary(model1)
#p-value: 2.2e-16
#R-squared: 0.2499 
#Min residual: -79.612
#Max residual: 78.996
#RSE: 19.72

#Turnovers and penalty yards are worse...?
model2 <- lm(PointDifferential ~ TurnoverDifferential + PenYdsDifferential, data=logs)
summary(model2)
#p-value: 2.2e-16
#R-squared: 0.2321 
#Min residual: -79.721
#Max residual: 82.474
#RSE: 19.95

#Is this the worst?
model3 <- lm(PointDifferential ~  InterceptionsDifferential + FumbleDifferential + PenYdsDifferential, data=logs)
summary(model3)
#p-value: 2.2e-16
#R-squared: 0.2499 
#Min residual: -79.670
#Max residual: 79.104
#RSE: 19.72

close_games <- logs %>%
  filter(PointDifferential < 9, PointDifferential >-9)

model_close_games <- lm(PointDifferential ~ InterceptionsDifferential + FumbleDifferential, data=close_games)
summary(model_close_games)
#p-value: 2.2e-16
#R-squared: 0.09807 
#Min residual: -11.2655
#Max residual: 11.1263



```

#Next, create a multiple regression model. Instead of using the number of penalties alone, combine other numeric columns that describe mistakes/bad outcomes to try and predict the score differential with a higher degree of confidence. Look at the same values in the results you did before, but also take into account the residual standard error and the risk of multicollinearity - are you adding columns that explain each other instead of the differential? Below this code block, explain your choices and what you think the results say.


#At the end of all that code, summarize what you've learned about the relationship between penalties and point differential and whether you think there's a story there or whether it's useful in adding context within a larger story. Would you use this in journalism and, if so, how?







